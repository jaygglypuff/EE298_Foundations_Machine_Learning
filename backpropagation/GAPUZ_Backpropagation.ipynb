{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foundations of Machine Learning EE298\n",
    "### Assignment No. 2 : Backpropagation\n",
    "#### Gapuz, Jay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset\n",
    "Supply the mean and standard deviation of a 1D Gaussian  \n",
    "For the given mean and std, draw 1,000,000 random samples from the 1D Gaussian  \n",
    "Build a dataset ùíü with 1,000 histogram bins \n",
    "  \n",
    "\n",
    "First create a normal Gaussian distribution, then create 1000 bins  \n",
    "Create a dataframe of the bin ranges and their frequency(P_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bins:  1000\n",
      "sum of P(x):  1.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low_lim</th>\n",
       "      <th>high_lim</th>\n",
       "      <th>p_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.501149</td>\n",
       "      <td>-2.496290</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.496290</td>\n",
       "      <td>-2.491430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.491430</td>\n",
       "      <td>-2.486571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.486571</td>\n",
       "      <td>-2.481711</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.481711</td>\n",
       "      <td>-2.476852</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2.334034</td>\n",
       "      <td>2.338893</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2.338893</td>\n",
       "      <td>2.343753</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2.343753</td>\n",
       "      <td>2.348612</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2.348612</td>\n",
       "      <td>2.353472</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2.353472</td>\n",
       "      <td>2.358331</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      low_lim  high_lim       p_x\n",
       "0   -2.501149 -2.496290  0.000001\n",
       "1   -2.496290 -2.491430  0.000000\n",
       "2   -2.491430 -2.486571  0.000000\n",
       "3   -2.486571 -2.481711  0.000000\n",
       "4   -2.481711 -2.476852  0.000000\n",
       "..        ...       ...       ...\n",
       "995  2.334034  2.338893  0.000000\n",
       "996  2.338893  2.343753  0.000000\n",
       "997  2.343753  2.348612  0.000000\n",
       "998  2.348612  2.353472  0.000001\n",
       "999  2.353472  2.358331  0.000001\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataset\n",
    "mean_val = 0\n",
    "std_val = 0.5\n",
    "\n",
    "dist = pd.DataFrame(\n",
    "    np.random.normal(mean_val, std_val, 1000000), \n",
    "    columns = [\"vals\"]\n",
    ")\n",
    "\n",
    "# Binning\n",
    "counts, bin_edges = np.histogram(dist, bins=1000)\n",
    "print(\"Total bins: \",len(counts))\n",
    "\n",
    "# Convert the frequency to P(x):\n",
    "counts = [i/1000000 for i in counts]\n",
    "print(\"sum of P(x): \", np.sum(counts))\n",
    "\n",
    "# Create a dataframe\n",
    "bins_arr = []\n",
    "for i in range(len(bin_edges)):\n",
    "    try:\n",
    "        bins_arr.append(\n",
    "            [bin_edges[i]-0.0000000000001,\n",
    "             bin_edges[i+1],\n",
    "             counts[i]]\n",
    "    )\n",
    "    except:\n",
    "        pass  \n",
    "bins_arr = pd.DataFrame(\n",
    "    bins_arr, \n",
    "    columns = [\"low_lim\", \"high_lim\", \"p_x\"]\n",
    ")\n",
    "\n",
    "# Check the bins\n",
    "bins_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dataframe containing 1 million samples from a 1D Gaussian,get each sample with the corresponding p(x) from the bins dataframe.   \n",
    "Code was based here: https://stackoverflow.com/questions/46179362/fastest-way-to-merge-pandas-dataframe-on-ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.882026</td>\n",
       "      <td>0.000799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200079</td>\n",
       "      <td>0.003498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.489369</td>\n",
       "      <td>0.002452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.120447</td>\n",
       "      <td>0.000294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.933779</td>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.727953</td>\n",
       "      <td>0.001312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>0.054512</td>\n",
       "      <td>0.003895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>-0.398641</td>\n",
       "      <td>0.002768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>0.437378</td>\n",
       "      <td>0.002686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.685915</td>\n",
       "      <td>0.001581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x         y\n",
       "0       0.882026  0.000799\n",
       "1       0.200079  0.003498\n",
       "2       0.489369  0.002452\n",
       "3       1.120447  0.000294\n",
       "4       0.933779  0.000682\n",
       "...          ...       ...\n",
       "999995  0.727953  0.001312\n",
       "999996  0.054512  0.003895\n",
       "999997 -0.398641  0.002768\n",
       "999998  0.437378  0.002686\n",
       "999999  0.685915  0.001581\n",
       "\n",
       "[1000000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals = pd.IntervalIndex.from_arrays(bins_arr.low_lim,bins_arr.high_lim, 'both')\n",
    "dataset = dist.assign(p_x=bins_arr.set_index(intervals).loc[dist.vals].p_x.values)\n",
    "dataset.columns = [\"x\",\"y\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset to train and test\n",
    "We will now create a dataset for training and testing.  \n",
    "We'll use 90 percent for training and 10 percent for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = np.split(\n",
    "    dataset.sample(frac=1, random_state=42), # for reproducibility\n",
    "    [int(.9*len(dataset))] #70 percent train\n",
    ")\n",
    "\n",
    "# Training data\n",
    "x_train = train[\"x\"].values\n",
    "x_train = x_train.reshape(len(x_train),1)\n",
    "y_train = train[\"y\"].values\n",
    "y_train = y_train.reshape(len(y_train),1)\n",
    "\n",
    "# Testing data\n",
    "x_test = test[\"x\"].values\n",
    "x_test = x_test.reshape(len(x_test),1)\n",
    "y_test = test[\"y\"].values\n",
    "y_test = y_test.reshape(len(y_test),1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the functions that will be used in the implementing the model\n",
    "\n",
    "This will include the activation function, forward propagation and backward propagation functions using the default Python functions and Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    # this will return values after RelU function is applied\n",
    "    return np.maximum(x,0)\n",
    "\n",
    "def ReLUDerivative(x):\n",
    "    # derivative of the ReLU\n",
    "    x[x <= 0] = 0\n",
    "    x[x >  0] = 1\n",
    "    \n",
    "    return x\n",
    "\n",
    "def activateLayer(inputs,weights):\n",
    "    # multiplying the weights and the input values\n",
    "    return np.dot(inputs,weights)\n",
    "\n",
    "def compute_loss(y_true,y_hat):\n",
    "    # Mean Square Error\n",
    "    return np.square(y_hat - y_true).sum()\n",
    "\n",
    "# forward propagation\n",
    "def forward_propagation(w1,w2,w3,w4,x):\n",
    "    # Input layer\n",
    "    h1 = activateLayer(x,w1)\n",
    "    h1_relu = ReLU(h1)\n",
    "    # Second layer\n",
    "    h2 = activateLayer(h1_relu,w2)\n",
    "    h2_relu = ReLU(h2)\n",
    "    # Third layer\n",
    "    h3 = activateLayer(h2_relu,w3)\n",
    "    # Output layer\n",
    "    h4 = activateLayer(h3,w4)\n",
    "    \n",
    "    return {\n",
    "        'input_layer': h1,\n",
    "        'ReLU_1': h1_relu,\n",
    "        'second_layer': h2,\n",
    "        'ReLU_2': h2_relu,\n",
    "        'third_layer': h3,\n",
    "        'output_layer': h4       \n",
    "    }   \n",
    "\n",
    "# backward propagation\n",
    "def backpropagate(X,y,z4,z3,relu_2,z2,relu_1,z1,w1,w2,w3,w4):\n",
    "    \n",
    "    # calculate error on the output \n",
    "    grad_z4 = 2 * (z4 - y)\n",
    "    grad_w4 = np.dot(z3.T,grad_z4)\n",
    "\n",
    "    # error on the third layer\n",
    "    grad_z3 = np.dot(grad_z4,w4.T)\n",
    "    grad_w3 = np.dot(relu_2.T,grad_z3)\n",
    "    \n",
    "    # error on the second_layer\n",
    "    grad_relu_2 = np.dot(grad_z3,w3.T)\n",
    "    grad_in_relu_2 = grad_relu_2.copy()\n",
    "    grad_in_relu_2 = ReLUDerivative(grad_in_relu_2)\n",
    "    grad_z2 = grad_in_relu_2\n",
    "    grad_w2 = np.dot(relu_1.T,grad_z2)\n",
    "    \n",
    "    # error on the first layer\n",
    "    grad_relu_1 = np.dot(grad_z2,w2.T)\n",
    "    grad_in_relu_1 = grad_relu_1.copy()\n",
    "    grad_in_relu_1 = ReLUDerivative(grad_in_relu_1)\n",
    "    grad_z1 = grad_in_relu_1\n",
    "    grad_w1 = np.dot(X.T,grad_z1)\n",
    "    \n",
    "    return {\n",
    "        'w1': grad_w1,\n",
    "        'w2': grad_w2,\n",
    "        'w3': grad_w3, \n",
    "        'w4': grad_w4\n",
    "    }\n",
    "\n",
    "def updateWeights(orig_weights,grad_weights,learning_rate):\n",
    "    orig_weights -= (learning_rate * grad_weights)\n",
    "    return orig_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create the training model\n",
    "\n",
    "Wrap all the functions used and then create the final training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "x = x_train\n",
    "y = y_train\n",
    "\n",
    "\n",
    "def train_customNeuralNetwork(no_of_epoch = 20,lr = 0.1):\n",
    "    \n",
    "    # Randomly initialize weights from a normal distribution\n",
    "    # with mean of 0 and standard deviation of 0.1\n",
    "    input_weights  = (0.1**2) * np.random.randn(1,64)\n",
    "    second_weights = (0.1**2) * np.random.randn(64,64)\n",
    "    third_weights  = (0.1**2) * np.random.randn(64,64)\n",
    "    output_weights = (0.1**2) * np.random.randn(64,1)\n",
    "    \n",
    "    \n",
    "    loss_arr = []\n",
    "    # Train the model:\n",
    "    for epoch in range(no_of_epoch):\n",
    "        \n",
    "        # Perform forward propagation\n",
    "        fwd_dict = forward_propagation(\n",
    "            input_weights,\n",
    "            second_weights,\n",
    "            third_weights,\n",
    "            output_weights,\n",
    "            x\n",
    "        )\n",
    "        \n",
    "        # Compute for the loss\n",
    "        loss_val = compute_loss(y,fwd_dict.get(\"output_layer\"))\n",
    "        loss_arr.append(loss_val)\n",
    "        print(\"epoch:\",epoch + 1, \"MSE: \", loss_val)\n",
    "        \n",
    "        # Perform backward propagation\n",
    "        bwd_dict = backpropagate(\n",
    "            x,y,\n",
    "            fwd_dict.get(\"output_layer\"),\n",
    "            fwd_dict.get(\"third_layer\"),\n",
    "            fwd_dict.get(\"ReLU_2\"),\n",
    "            fwd_dict.get(\"second_layer\"),\n",
    "            fwd_dict.get(\"ReLU_1\"),\n",
    "            fwd_dict.get(\"input_layer\"),\n",
    "            input_weights,\n",
    "            second_weights,\n",
    "            third_weights,\n",
    "            output_weights\n",
    "        )\n",
    "        \n",
    "        # Update the weights\n",
    "        input_weights = updateWeights(input_weights, bwd_dict.get('w1'), lr)\n",
    "        second_weights = updateWeights(second_weights, bwd_dict.get('w2'), lr)\n",
    "        third_weights = updateWeights(third_weights, bwd_dict.get('w3'), lr)\n",
    "        output_weights = updateWeights(output_weights, bwd_dict.get('w4'), lr)\n",
    "        \n",
    "    return(input_weights,second_weights,third_weights,output_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 MSE:  7.820041608503616\n",
      "epoch: 2 MSE:  516.6032952269815\n",
      "epoch: 3 MSE:  7.818729069117002\n",
      "epoch: 4 MSE:  7.818729069117002\n",
      "epoch: 5 MSE:  7.818729069117002\n",
      "epoch: 6 MSE:  7.818729069117002\n",
      "epoch: 7 MSE:  7.818729069117002\n",
      "epoch: 8 MSE:  7.818729069117002\n",
      "epoch: 9 MSE:  7.818729069117002\n",
      "epoch: 10 MSE:  7.818729069117002\n",
      "epoch: 11 MSE:  7.818729069117002\n",
      "epoch: 12 MSE:  7.818729069117002\n",
      "epoch: 13 MSE:  7.818729069117002\n",
      "epoch: 14 MSE:  7.818729069117002\n",
      "epoch: 15 MSE:  7.818729069117002\n",
      "epoch: 16 MSE:  7.818729069117002\n",
      "epoch: 17 MSE:  7.818729069117002\n",
      "epoch: 18 MSE:  7.818729069117002\n",
      "epoch: 19 MSE:  7.818729069117002\n",
      "epoch: 20 MSE:  7.818729069117002\n"
     ]
    }
   ],
   "source": [
    "# Now call the main routine and train the network\n",
    "model = train_customNeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate and evaluate the model performance\n",
    "\n",
    "Call all the weights and then recreate the forward propagation function.\n",
    "Use the test data and evaluate the overall MSE of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on test data: 0.8680629860769999\n"
     ]
    }
   ],
   "source": [
    "test_arr = forward_propagation(\n",
    "    model[0],\n",
    "    model[1],\n",
    "    model[2],\n",
    "    model[3],\n",
    "    x_test\n",
    ")\n",
    "print(\"MSE on test data:\", compute_loss(test_arr.get('output_layer'),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
